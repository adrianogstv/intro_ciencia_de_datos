{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos frecuentistas\n",
    "\n",
    "Al analizar datos, se puede pensar en dos grandes alternativas:\n",
    "\n",
    "* Pruebas de hipótesis\n",
    "* Estimación del tamaño de un efecto junto con la determinación de la incertidumbre\n",
    "\n",
    "La primera de estas estrategias es la que tradicionalmente se ha enseñado y divulgado con más énfasis. La segunda estrategia se la ha llamado \"[nueva estadística](https://www.amazon.com/Understanding-New-Statistics-Meta-Analysis-Multivariate/dp/041587968X)\" (sobre todo dentro del campo de la estadística aplicada a problemas en psicología experimental).\n",
    "\n",
    "Ambas aproximaciones pueden encararse desde una posición frecuentista o Bayesiana. En este capítulo veremos la forma frecuentista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de hipotesis\n",
    "\n",
    "La prueba de hipótesis,también llamada test de hipótesis o prueba de significación, es un procedimiento para establecer si una propiedad dada de una población es compatible con lo observado en una muestra de dicha población.\n",
    "\n",
    "\n",
    "1. Calculamos un _estadístico_ $T(\\mathcal{D})$ es decir una medida cuantitativa que describe nuestros datos $\\mathcal{D}$\n",
    "\n",
    "2. Generaremos una hipótesis nula $H_{0}$, es decir la hipótesis del no-efecto y asumiendo $H_{0}$ calculamos $T(\\mathcal{\\tilde D})$\n",
    "\n",
    "3. Calculamos $valor p \\triangleq p(T(\\mathcal{\\tilde D}) \\ge T(\\mathcal{D}) ) | H_{0}, I)$. Es decir la probabilidad de obtener un estadístico al menos tan extremo como el observado, asumiendo  $H_{0}$ como cierto.\n",
    "\n",
    "4. Evaluamos si el _valor p_ es _pequeño o grande_. Para esto usamos un valor predefinido, el cual suele ser $\\alpha = 0.05$. Si $p < \\alpha$ entonces se dice que \"rechazamos $H_0$\" si en cambio $p \\ge \\alpha$ se dice que \"fallamos en rechazar $H_0$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de la moneda según la hipótesis nula\n",
    "\n",
    "Vamos con un ejemplo sencillo, que nos acompañará por un buen rato. Supongamos que tiramos al aire 20 veces una misma moneda y observamos 7 caras y 13 cecas.\n",
    "\n",
    "¿Es compatible la idea de una moneda que cae la mitad de las veces cara y la mitad ceca con estos datos?\n",
    "\n",
    "En el ejemplo de la moneda un estadístico podría ser la cantidad de caras $z$ para $n$ tiradas. La hipótesis nula sería que tenemos el mismo número de caras que de cecas, $H_{0} = 0.5$. \n",
    "\n",
    "Un par de cosas a notar son que:\n",
    "\n",
    "* Bajo el paradigma frecuentista no es posible aceptar una hipótesis nula. Por eso los frecuentistas dicen \"fallamos en rechazar $H_0$\".\n",
    "* El computo del *valor p* asume que $H_{0}$ es cierta. Por lo tanto el *valor p* NO es la probabilidad que $H_{0}$ sea cierta, tampoco es la probabilidad de $no H_0$ (la alternativa) sea cierta, ni siquiera es $p(\\mathcal{D} | H_0)$.\n",
    "* Bajo el paradigma frecuentista no es posible preguntarse sobre la probabilidad de un parámetro tome tal o cual valor. Los parámetros tienen valores fijos (aunque desconocidos). Por lo tanto NO podemos responder a la pregunta ¿Cuál es la probabilidad que nuestra moneda esté sesgada? $p(\\theta = 0.5 | \\mathcal{D})$\n",
    "\n",
    "\n",
    "Ahora que conocemos el modo de pensar frecuentista veamos como aplicarlo para resolver el problema de la moneda.\n",
    "\n",
    "Este problema puede ser resuelto de forma analítica, basta aplicar la distribución binomial ¿Por qué esta distribución? Precisamente por que modela eventos que tienen dos posibles resultados, cara-ceca, si-no, apagado-prendido, sano-enfermo, etc. La distribución binomial la vimos en el capítulo anterior y tiene la siguiente forma:  \n",
    "\n",
    "$$p(x|n,p) = {\\binom {n}{k}}p^x(1-p)^{n-x}$$\n",
    "\n",
    "\n",
    "Hay que tener cuidado que $p$ en la distribución binomial NO es el _valor p_ del que estabamos hablando! Este es un buen momento para  volver al capítulo anterior y revisar _como es_ esta distribución.\n",
    "\n",
    "\n",
    "A continuación vamos a generar los datos con Python, _como si_ hubiéramos arrojado la moneda 20 veces y hubiéramos observado 7 caras. Vamos a usar el número 1 para representar caras y el 0 para representar cecas. Manipular números es mucho más simple que manipular _strings_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monedas_obs = [1] * 7 + [0] * 13\n",
    "# una forma alternativa a la linea de arriba, pero usando NumPy\n",
    "# monedas_obs = np.repeat((1, 0), (7, 13)) \n",
    "len(monedas_obs), sum(monedas_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el paradigma frecuentista el procedimiento sería:\n",
    "\n",
    "1. Vamos a asumir que la moneda tiene la misma chance de caer cara (1) o ceca (0), p = 0.5\n",
    "2. Vamos a lanzar una moneda 20 veces (igual que en nuestros datos), n = 20\n",
    "3. Dados los puntos 1 y 2 y asumiendo que la moneda sigue una distribución binomial (con n=20, p =0.5) vamos a calcular la probabilidad de obtener 7 o menos caras. Esto es el *valor p*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20   # cantidad de veces que arrojamos la moneda en el experimento\n",
    "p = 0.5  # si H0 entonces p=0.5 (igual proporción de caras y cecas)\n",
    "caras_obs = sum(monedas_obs) \n",
    "dist_monedas = stats.binom(n, p);\n",
    "x = np.arange(0, n + 1)\n",
    "y = dist_monedas.pmf(x)\n",
    "valor_p = sum(y[:caras_obs+1])\n",
    "plt.vlines(x, 0, y, 'C0')\n",
    "plt.vlines(x[:caras_obs+1], 0, y[:caras_obs+1], 'C2',\n",
    "           label='p = {:.3f}'.format(valor_p))\n",
    "plt.legend()\n",
    "plt.xticks(x)\n",
    "plt.xlabel('z');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretando los resultados\n",
    "\n",
    "Recapitulemos lo que acabamos de hacer es calcular la probabilidad de obtener 0, 1, ... 20 caras (barras azules), esto se llama _distribución de muestreo (sampling distribution)_. Y es la distribución de nuestro _estadístico_ $z$ para una muestra finita de $n=20$. \n",
    "\n",
    "Esta distribución es central en estadística frecuentista. De hecho a partir de ella hemos calculado la probabilidad de obtener 7 o menos caras (barras naranja), el _valor p_. \n",
    "\n",
    "¿Cómo se interpreta el _valor p_? \n",
    "\n",
    "Bueno, desde el punto de vista frecuentista las probabilidades viven en _asintópia_ un mundo donde las probabilidades son frecuencias que se obtienen en el límite de infinitas repeticiones de un mismo experimento. Entonces la interpretación sería:\n",
    "\n",
    "    Si arrojaramos 20 veces al aire una moneda NO SESGADA y esto lo repetimos infinitas veces entonces el 13.2 % de las veces obtendremos 7 o menos caras. \n",
    "\n",
    "Es decir hemos encontrado la respuesta al pregunta ¿Cuán _esperable_ es este resultado para una moneda que _debería_ caer la mitad de las veces cara?\n",
    "\n",
    "Otra pregunta _natural_ sería ¿Es realmente _diferente_ este resultado de $H_0$? Para dar respuesta a esta pregunta se suele usar el concepto (o \"confupto\" es decir concepto confuso) de significancia estadística, que consiste, como ya adelantamos, en comparar el _valor p_ con el valor predeterminado $\\alpha$:\n",
    "\n",
    "* Si p < 0.05, entonces la diferencia es estadísticamente significativa\n",
    "* Si p < 0.001, entonces la diferencia es estadísticamente altamente-significativa\n",
    "\n",
    "En este caso como p > 0.05 diríamos: \"Se falla en rechazar la hipótesis nula con un p=0.132 y un nivel de significancia de 0.05\".\n",
    "\n",
    "Si esto suena a _rito umbanda_ es por que algo de eso hay! ¿De donde salen esos números? La verdad es que son arbritrarios y son casi consecuencia de accidentes históricos. Lamentablemente se ha vuelto muy común que estos límites se utilicen para definir si resultados son publicables o no. El límite dependerá de la revista/disciplina, siendo 0.05 común por ej en psicología y en varias ramas de la biología.\n",
    "\n",
    "La intención de fijar un valor de $\\alpha = 0.05$ es la de controlar el nivel de errores de tipo I. Es decir las falsas alarmas o más formalemente controlar la cantidad de veces que estamos dispuestos a rechazar una hipótesis nula verdadera (es decir una que NO deberíamos haber rechazado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problemas con las prueba de hipótesis nula\n",
    "\n",
    "Esta aproximación tiene varios problemas\n",
    "\n",
    "1. Impone una forma de pensar dicotómica, que suele ser inapropiada en la mayoría de los estudios científicos.\n",
    "2. Los *valor p* omiten muchos factores, información previa, nivel de precisión/incerteza de la estimación.\n",
    "3. Un efecto estadísticamente significativo no tiene por que ser un efecto relevante.\n",
    "4. Los _valores p_ dependen de las intenciones del observador! Si el experimento A es tirar $N$ veces una moneda y contar el número de caras y el experimento B es tirar una moneda hasta que obtener $z$ caras. El _valor p_ no necesariamente es el mismo aún si en ambos experimentos observamos que $N=10, z=7$). La razón es que las _distribuciones de muestro_ son diferentes en ambos casos, aún cuando los datos sean idénticos.\n",
    "5. En general los *valores p* son interpretados erroneamente. Un trabajo mostró que solo el 62% de los encuestados fue capaz de contestar de forma correcta sobre la definición de los *valores p*. Lo interesante es que en realidad ninguna de las respuestas provistas en este estudio correspondía a una definición correcta de los _valores p_! Los *valores p* NO son:\n",
    "    * La probabilidad de que $H_0$ sea cierta\n",
    "    * La probabilidad de que $ no H_0$ falsa\n",
    "    * La probabilidad de cometer un error al rechazar $H_0$\n",
    "    * La probabilidad de que los datos observados se hayan dado por *azar*\n",
    "    * Una forma de indicar que NO hay efecto si p > 0.5 (o el nivel que sea)\n",
    "    * Una medida de la *relevancia* de un efecto.\n",
    "    \n",
    "\n",
    "Gran parte de los problemas derivados de los *valores p*, provienen de usarlos como parte de la maquinaria de \"prueba de hipótesis nula\". La otra parte del problema de usar los _valores p_ proviene quizá de que estos no derivan de un sistema formal de cálculo de probabilidades si no que fueron introducidos de forma totalmente _ad hoc_. Como veremos más adelante la Estadística Bayesiana provee de algo llamado factores de Bayes que curiosamente es todo lo que usted siempre quiso que un _valor p_ fuera, pero que el _valor p_ NO puede ser.\n",
    "\n",
    "Una forma de usar los _valores p_ sin meter la pata es no pedirle que ofrezcan la información que no pueden ofrecer. Un _valor p_ debería ser usado con el fin que originalmente se postuló: Una forma aproximada, cuando se cuenta con poca información sobre un problema, para intentar estimar (de forma objetiva) si vale la pena seguir mirando los datos o haciendo experimentos a fin de replicar o extender resultados. Entonces en general valores \"bajos\" de los _valores p_ indicarían que es posible que tengamos algo interesante. Por ejemplo algunos autores recomiendan de forma _muuuy_ general interpretar los _valores p_ de la siguiente manera \n",
    "\n",
    "* p < 0.01 Hey parece que tenemos algo! :-)\n",
    "* p > 0.1 humm al parecer no hay mucho que decir :-(\n",
    "* 0.01 < p < 0.1 La vida rara vez nos ofrece respuestas claras! :-|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruebas de una y dos colas\n",
    "\n",
    "...Tener en cuenta que hemos calculado solo una cola de la distribución, obtener  las caras obtenidas o menos. Podríamos haber preguntado la probabildiad de obtener menos de 7 caras o menos de 7 cecas.... Lo primero se llama \"prueba de una cola\", el segundo \"prueba de dos colas\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los _valores p_ se pueden calcualr de forma directa, sin necesidad de hacer simulaciones, si conocemos la cdf de la distribución de muestreo. Usando SciPy esto es simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_monedas.cdf(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " si p=0.5 entonces la distribución es simétrica por lo tanto si queremos calcular la probabilidad de valores \"extremos\" para ambas colas solo tenemos que multiplicar por 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_monedas.cdf(7) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores p por simulación\n",
    "\n",
    "Supongamos que son un poco escépticos sobre el uso de la distribución binomial, para resolver estre problema. Una alternativa al cálculo analítico que acabamos de hacer es usar Python para simular que arrojamos nonedas al aire!\n",
    "\n",
    "1. Vamos a asumir que la moneda tiene la misma chance de caer cara (1) o ceca (0)\n",
    "2. Vamos a lanzar una moneda 20 veces (igual que en nuestros datos)\n",
    "3. Vamos a repetir el punto 2, una gran catidad de veces (por ej 10000 más o menos)\n",
    "4. Vamos a contar todas las veces que obtengamos 7 o menos caras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(monedas_obs)\n",
    "caras_sim_l = []\n",
    "ite = 10000\n",
    "for i in range(0, ite):\n",
    "    monedas_sim = np.random.randint(0, 2, size=n)\n",
    "    caras_sim = sum(monedas_sim)\n",
    "    caras_sim_l.append(caras_sim)\n",
    "x = np.arange(0, n + 1)\n",
    "y = np.histogram(caras_sim_l, np.arange(0, n+1), normed=True)[0]\n",
    "# como y está normalizado, esta linea es una probabilidad\n",
    "valor_p = sum(y[:caras_obs+1])\n",
    "plt.vlines(x, 0, y, 'C0')\n",
    "plt.vlines(x[:caras_obs+1], 0, y[:caras_obs+1], 'C2',\n",
    "           label='p = {:.3f}'.format(valor_p))\n",
    "plt.legend()\n",
    "plt.xticks(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxima verosimilitud e intervalos de  confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, al parecer los *valores p* y la idea de la prueba de hipótesis nulas no son del todo buenas ideas. Una solución a este problema (sin abandonar las ideas frecuentistas) es tratar de hacer una estimación puntual que resuma lo observado. Un ejemplo de estimación puntual es la media de una muestra.\n",
    "\n",
    "Suele ser buena idea acompañar la estimación puntual con una medida de la incertidumbre asociada a la estimación puntual. La idea es contar con una estimación del rango de valores plausibles.\n",
    "\n",
    "1. Una estimación puntual es el valor más plausible de un parámetro, por lo tanto tiene sentido indicar la incerteza alrededor de el.\n",
    "2. La plausibilidad del intervalo de confianza se puede construir partir de la distribución de muestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_monedas = stats.binom(n=20, p=7/20)\n",
    "media = dist_monedas.mean()\n",
    "std_error =  dist_monedas.std()/n\n",
    "li = std_error * 1.96  # esta cantidad se resta a la media\n",
    "ls = std_error * 1.96  # esta cantidad se suma a la media\n",
    "\n",
    "plt.errorbar(x=media, y=0, xerr=[[li, ls]], fmt='o')\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mostrar como calcular MLE en general\n",
    "* Mostrar minimos cuadrados como caso particular\n",
    "* Mostrar como usar bootstrtaping con la regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. graficar dist_monedas.cdf() en el rango de 0 a 20. Luego lo mismo pero para un n más grande  por ejmplo 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
